# üöÄ Table Stream Query Engine (TSQE) PoC: Arquitetura de Dados de Pr√≥xima Gera√ß√£o

## Por Elias Andrade | Next-Gen System & Data Architect

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Elias%20Andrade-0077B5?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/itilmgf/)
[![GitHub](https://img.shields.io/badge/GitHub-chaos4455-181717?style=for-the-badge&logo=github)](https://github.com/chaos4455)
[![Python](https://img.shields.io/badge/Python-3.11+-3776AB?style=for-the-badge&logo=python)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/Framework-FastAPI-009688?style=for-the-badge&logo=fastapi)](https://fastapi.tiangolo.com/)
[![DuckDB](https://img.shields.io/badge/DB%20Engine-DuckDB-075e81?style=for-the-badge&logo=data-ingestion)](https://duckdb.org/)
[![PyArrow](https://img.shields.io/badge/Format-PyArrow%2FParquet-e36611?style=for-the-badge&logo=apache-arrow)](https://arrow.apache.org/)

<img width="1536" height="1024" alt="ChatGPT Image 20 de jan  de 2026, 11_12_57" src="https://github.com/user-attachments/assets/1bef46b4-bfe4-4204-bdf5-4c608753354d" />


---

## I. üí° Introdu√ß√£o Estrat√©gica: O Conceito de Table Stream Query Engine

Esta Prova de Conceito (PoC) demonstra a constru√ß√£o de uma arquitetura de dados *Lean* e desacoplada, utilizando microsservi√ßos customizados para resolver o desafio cl√°ssico de transformar **streams de dados de alta velocidade** em **insights em tempo real**, com lat√™ncia ultrabaixa, sem a complexidade operacional de Data Lakes massivos ou clusters Kafka gen√©ricos para casos de uso espec√≠ficos.

### O que √© o TSQE?

O **Table Stream Query Engine (TSQE)** √© um motor de processamento h√≠brido que trata dados de streaming como uma tabela permanentemente materializada e instantaneamente consult√°vel. Em vez de simplesmente enfileirar eventos (como o Kafka), ou armazenar em disco (como bancos de dados tradicionais), o TSQE **mant√©m o estado atual da realidade** em mem√≥ria, permitindo consultas OLAP (Online Analytical Processing) complexas sobre o estado *atualizado* do sistema com lat√™ncia de milissegundos.

**Caso de Uso Pr√°tico (Esta PoC):** Monitoramento de sensores de temperatura em supermercados. A cada 10 segundos, o estado de centenas de freezers √© atualizado (UPSERT), permitindo que um Dashboard Anal√≠tico consulte o status de toda a rede usando SQL puro, em tempo real.

---

## II. üèõÔ∏è Arquitetura de Microsservi√ßos Desacoplados (Decoupled Architecture)

A solu√ß√£o √© dividida em tr√™s microsservi√ßos independentes, comunicando-se exclusivamente via APIs e formatos de dados padronizados (JSON, PyArrow). Este modelo garante escalabilidade, resili√™ncia e a capacidade de trocar componentes sem afetar o sistema principal (Engine).

| Camada | Componente | Tecnologia Principal | Fun√ß√£o Prim√°ria |
| :--- | :--- | :--- | :--- |
| **Data Producer** | üíâ **Data Injector (Simulador)** | Python, `requests`, `faker` | Simula um grande volume de sensores (Upserts). |
| **Data Engine/Store** | ‚öôÔ∏è **TSQE (Engine Principal)** | FastAPI, DuckDB, PyArrow | Ingest√£o multi-formato, Armazenamento in-memory e Execu√ß√£o de Query SQL. |
| **Data Consumer** | üìä **Dashboard & Metrics Collector** | FastAPI, HTML/JS, `requests` | Consulta a Engine, calcula KPIs em tempo real e renderiza a visualiza√ß√£o Web. |

### Comunica√ß√£o Ass√≠ncrona e Sincronizada

1. **Injector ‚û°Ô∏è TSQE:** Usa chamadas **POST `/ingest`** para realizar `UPSERTs` (Insert/Update) de forma transacional no estado da tabela em tempo real.
2. **Dashboard ‚û°Ô∏è TSQE:** Usa chamadas **POST `/query`** enviando consultas SQL complexas. A Engine retorna o resultado em um formato otimizado (JSON serializado por PyArrow) em menos de 100ms.

---

## III. üß† O Cora√ß√£o da Engine: DuckDB e PyArrow

A performance e o poder anal√≠tico do TSQE residem na escolha de ferramentas de pr√≥xima gera√ß√£o:

### 1. DuckDB: O Swiss Army Knife do OLAP

DuckDB √© um **banco de dados anal√≠tico in-process** que se integra nativamente ao Python. Suas principais vantagens nesta arquitetura s√£o:

*   **OLAP Power:** Permite executar o SQL anal√≠tico complexo (`GROUP BY`, `TRY_CAST`, `JSON_EXTRACT`) diretamente sobre o stream de dados em mem√≥ria, algo impratic√°vel em bancos de dados operacionais (OLTP).
*   **Performance In-Memory:** Utiliza o modelo de processamento vetorial (columnar) para consultas extremamente r√°pidas, essenciais para o requisito de baixa lat√™ncia do Dashboard.
*   **Transa√ß√µes de Stream (`UPSERT`):** A l√≥gica de ingest√£o utiliza comandos `INSERT... ON CONFLICT DO UPDATE...` para garantir que o estado do sensor seja sempre o mais recente, tratando o *stream* como uma tabela de fatos atualiz√°vel.

### 2. PyArrow: A Linguagem Universal de Dados

O Apache Arrow (implementado em Python via PyArrow) √© fundamental para a interoperabilidade e efici√™ncia:

*   **Ingest√£o Multi-Formato:** A Engine aceita dados via JSON, YAML ou at√© mesmo o formato Parquet (baseado em Arrow), demonstrando flexibilidade de ingest√£o.
*   **Performance na Query:** O DuckDB retorna os resultados no formato `Arrow Table`. Isso permite que a Engine converta os dados para JSON de sa√≠da de forma altamente eficiente, garantindo que a serializa√ß√£o n√£o se torne o gargalo de lat√™ncia. O uso da `json_converter` customizada na Engine resolve o desafio comum de serializar tipos de dados (como `datetime`) do PyArrow para JSON padr√£o.

---

## IV. üìä L√≥gica de Processamento no Dashboard (Consumer Side Analytics)

O servi√ßo **Dashboard Metrics Collector** atua como um microsservi√ßo de *Analytics Edge*, onde a l√≥gica de neg√≥cio mais leve e espec√≠fica √© executada, mantendo a Engine principal focada apenas na entrega de dados brutos e r√°pidos.

### Fluxo de Gera√ß√£o de KPIs:

1.  **Consulta SQL Eficiente:** O Consumer envia um `SELECT *` simples para obter o estado atual de *todos* os sensores na `real_time_stream_data`.
2.  **Processamento Python:** Uma vez que os dados brutos chegam como uma lista de dicion√°rios, o Python (FastAPI) assume a carga anal√≠tica:
    *   **KPIs Globais:** Contagem total, contagem de alertas, e status de sa√∫de da pr√≥pria Engine (baseado na lat√™ncia de consulta).
    *   **KPIs por Entidade (Filial/Branch):** Agrega√ß√£o e c√°lculo de m√©tricas como:
        *   `Total de Sensores por Filial`
        *   `M√©dia de Temperatura` (`avg_temperature`)
        *   `Percentual de Sensores em Alerta` (`percent_alert`)
3.  **Visualiza√ß√£o:** O Consumer serve uma interface HTML/CSS/JS (altamente otimizada para performance) que chama sua pr√≥pria API a cada 10 segundos, atualizando dinamicamente os cart√µes KPI e a tabela detalhada das filiais.

Esta separa√ß√£o (SQL r√°pido na Engine + Agrega√ß√£o customizada no Consumer) garante que o sistema seja **altamente customiz√°vel** e que o Dashboard possa facilmente adaptar suas m√©tricas sem exigir altera√ß√µes complexas na Engine.

---

## V. üéØ Posicionamento Estrat√©gico: Customiza√ß√£o vs. Ferramentas COTS

Em meu papel como **Next-Gen System & Data Architect**, defendo a arquitetura *Lean* para desafios de dados espec√≠ficos, conforme demonstrado por esta PoC:

### Por que Microsservi√ßos Customizados Superam Ferramentas de Prateleira?

| Ferramenta de Prateleira (Ex: Kafka, Data Lake, DB Relacional) | Arquitetura TSQE Customizada (FastAPI + DuckDB) |
| :--- | :--- |
| **Overhead Operacional:** Exige clusters complexos (Kafka), ETL pipelines ou infraestrutura de armazenamento massiva. | **Lean Architecture:** Infraestrutura m√≠nima (tr√™s aplica√ß√µes Python leves). Custos operacionais e de manuten√ß√£o baix√≠ssimos. |
| **Lat√™ncia Vari√°vel:** Consulta anal√≠tica em Data Lakes pode levar segundos; Kafka √© √≥timo para eventos, ruim para o estado atual agregado. | **Lat√™ncia Determin√≠stica:** Consultas anal√≠ticas em mem√≥ria (DuckDB) garantem performance de **sub-100ms** para relat√≥rios em tempo real. |
| **Acoplamento:** Muitas vezes, o Consumer fica acoplado ao formato do T√≥pico (Kafka) ou do Schema (DB). | **Decoupled Architecture:** A Engine exp√µe um contrato de Query API (`/query`). Fontes e Consumidores podem ser trocados livremente, garantindo flexibilidade. |
| **Generalista:** Ferramentas s√£o projetadas para o uso mais amplo, resultando em funcionalidades n√£o utilizadas. | **Otimizado para a Miss√£o:** Cada componente √© especificamente otimizado para o caso de uso (Ingest√£o de Upsert e Query Anal√≠tica). |

Esta PoC √© uma evid√™ncia pr√°tica da minha capacidade de projetar **solu√ß√µes de dados robustas, customiz√°veis e sob controle total**, que entregam valor de neg√≥cio com a m√°xima efici√™ncia t√©cnica.

---

## VI. üõ†Ô∏è Stack Tecnol√≥gica (Resumo)

| Categoria | Tecnologia | Justificativa |
| :--- | :--- | :--- |
| **API & Service Layer** | Python 3.11+, FastAPI, Uvicorn | Framework moderno, ass√≠ncrono e de alta performance para construir APIs de microsservi√ßos. |
| **Data Processing Core**| DuckDB (in-memory) | Banco de dados anal√≠tico in-process para consultas r√°pidas e manipula√ß√£o eficiente de dados vetoriais. |
| **Data Interoperability**| PyArrow, Parquet, JSON | Padroniza√ß√£o do formato de dados para transfer√™ncia de alta velocidade entre servi√ßos Python. |
| **Simula√ß√£o/Testing** | `Faker`, `requests` | Gera√ß√£o de dados simulados realistas para provar a capacidade de ingest√£o cont√≠nua. |
| **Web UI** | HTML5, CSS3, Vanilla JS | Interface leve e auto-refreshing para demonstrar o consumo de dados em tempo real. |

---

## VII. ‚öôÔ∏è Como Executar a PoC (Setup Simplificado)

Para replicar esta arquitetura:

1.  Clone o reposit√≥rio.
2.  Instale as depend√™ncias: `pip install fastapi uvicorn duckdb pyarrow requests pydantic faker starlette pyyaml`
3.  Inicie os tr√™s microsservi√ßos em terminais separados:
    *   **Engine (Porta 8888):** (Executar o arquivo Server Engine)
    *   **Dashboard (Porta 8080):** (Executar o arquivo Consumer Dashboard)
    *   **Injector:** (Executar o arquivo Data Injector)
4.  Acesse o Dashboard em `http://127.0.0.1:8080/` e observe as m√©tricas globais e por filial atualizando a cada 10 segundos, provando a baixa lat√™ncia da Engine.

---

## üë®‚Äçüíª Contato

Este projeto √© um exemplo de minhas habilidades em projetar e implementar arquiteturas de dados de ponta.

**Elias Andrade**
*   **T√≠tulo:** Next-Gen System & Data Architect
*   **GitHub:** `chaos4455`
*   **LinkedIn:** [linkedin.com/in/itilmgf](https://www.linkedin.com/in/itilmgf/)
